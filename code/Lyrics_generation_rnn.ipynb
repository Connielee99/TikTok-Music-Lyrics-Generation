{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /home/yuz522/.local/lib/python3.7/site-packages (0.42.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Install jieba for Chinese text segmentation \n",
    "!pip install jieba --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "tf.enable_eager_execution()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of lyrics\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data/lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in lyrics\n",
    "text_all = ''\n",
    "for song in os.listdir(data_dir):\n",
    "    if song.endswith('.txt'):\n",
    "        text = open(os.path.join(data_dir, song), mode = 'rb').read().decode(encoding = \"utf-8\")\n",
    "        text_all += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.225 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use Jieba to segment lyrics into words\n",
    "text_all = jieba.lcut(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3476 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Save a unique words into vocab\n",
    "vocab = sorted(set(text_all))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word to index mapping\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice lyrics data into sequences\n",
    "seq_length = 20\n",
    "examples_per_epoch = len(text_all) // seq_length\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs and outputs\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder = True)\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and prepare dataset for training\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "rnn_units = 1024\n",
    "lstm_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU versions of RNN and LSTM layers \n",
    "rnn = tf.keras.layers.CuDNNGRU\n",
    "lstm = tf.keras.layers.CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "def build_model_lstm(vocab_size, embedding_dim, lstm_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "        batch_input_shape = [batch_size, None]),\n",
    "    lstm(lstm_units,\n",
    "        return_sequences = True, \n",
    "        recurrent_initializer = 'glorot_uniform',\n",
    "        stateful = True),\n",
    "    lstm(lstm_units,\n",
    "        return_sequences = True, \n",
    "        recurrent_initializer = 'glorot_uniform',\n",
    "        stateful = True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN model\n",
    "def build_model_rnn(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "        batch_input_shape = [batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences = True, \n",
    "        recurrent_initializer = 'glorot_uniform',\n",
    "        stateful = True),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences = True, \n",
    "        recurrent_initializer = 'glorot_uniform',\n",
    "        stateful = True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN model\n",
    "model_rnn = build_model_rnn(\n",
    "    vocab_size = len(vocab), \n",
    "    embedding_dim = embedding_dim, \n",
    "    rnn_units = rnn_units, \n",
    "    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model_lstm = build_model_lstm(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dim = embedding_dim, \n",
    "    lstm_units = lstm_units,\n",
    "    batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile RNN model with loss and optimizer\n",
    "model_rnn.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile LSTM model with loss and optimizer \n",
    "model_lstm.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints for RNN model\n",
    "checkpoint_dir_rnn = './Lyrics_training_rnn'\n",
    "\n",
    "checkpoint_prefix_rnn = os.path.join(checkpoint_dir_rnn, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback_rnn = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix_rnn,\n",
    "    save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints for LSTM model\n",
    "checkpoint_dir_lstm = './Lyrics_training_lstm'\n",
    "\n",
    "checkpoint_prefix_lstm = os.path.join(checkpoint_dir_lstm, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback_lstm = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix_lstm,\n",
    "    save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "14/14 [==============================] - 5s 367ms/step - loss: 7.6494\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 6.3409\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 6.1336\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 5.9505\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 5.7122\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 5.4185\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 5.1146\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.8023\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 4.4530\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 4.0795\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 3.6730\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 3.2500\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 2s 107ms/step - loss: 2.8657\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 2.5298\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 2.2188\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 1.9456\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 1.7279\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 1.5387\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 1.3761\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 1.2392\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 1.1227\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 1.0129\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.9393\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.8711\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.8036\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.7440\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.6943\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.6526\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.6204\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.5820\n"
     ]
    }
   ],
   "source": [
    "# Train RNN model\n",
    "history = model_rnn.fit(dataset.repeat(), \n",
    "                    epochs = 30, \n",
    "                    steps_per_epoch = steps_per_epoch, \n",
    "                    callbacks = [checkpoint_callback_rnn]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 3s 244ms/step - loss: 6.8564\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 6.1730\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 6.1086\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 6.0728\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 6.0001\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 5.8402\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 5.6822\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 2s 107ms/step - loss: 5.4996\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 5.2966\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 5.0884\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 4.8715\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 4.6428\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 4.4044\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 4.1557\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 3.8993\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 3.6511\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 3.3994\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 3.1418\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 2.9270\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 2.6984\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 2.4929\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 2.3110\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 2.1300\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 1.9673\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 1.8126\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 2s 129ms/step - loss: 1.6786\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 1.5491\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 1.4456\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 1.3378\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 1.2482\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 1.1650\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 1.0855\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 1.0222\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.9590\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 0.8990\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.8575\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 0.8104\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.7776\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 2s 133ms/step - loss: 0.7356\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.6928\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.6701\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.6393\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.6108\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.5943\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.5700\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.5478\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.5320\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.5247\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4987\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4888\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "history = model_lstm.fit(dataset.repeat(), \n",
    "                    epochs = 50, \n",
    "                    steps_per_epoch = steps_per_epoch, \n",
    "                    callbacks = [checkpoint_callback_lstm],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN model using weights in the last checkpoint\n",
    "model_rnn = build_model_rnn(vocab_size, embedding_dim, rnn_units, batch_size = 1)\n",
    "model_rnn.load_weights(os.path.join(checkpoint_dir_rnn, 'ckpt_30'))\n",
    "model_rnn.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model using weights in the last checkpoint\n",
    "model_lstm = build_model_lstm(vocab_size, embedding_dim, lstm_units, batch_size = 1)\n",
    "model_lstm.load_weights(os.path.join(checkpoint_dir_lstm, 'ckpt_50'))\n",
    "model_lstm.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 300)            1042800   \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 1024)           4073472   \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (1, None, 1024)           6297600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 3476)           3562900   \n",
      "=================================================================\n",
      "Total params: 14,976,772\n",
      "Trainable params: 14,976,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN model summmary\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 300)            1042800   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (1, None, 1024)           5431296   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (1, None, 1024)           8396800   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 3476)           3562900   \n",
      "=================================================================\n",
      "Total params: 18,433,796\n",
      "Trainable params: 18,433,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM model summary\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating function\n",
    "def generate_text(model, start_string, temperature = 1, num_generate = 100):\n",
    "    \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of results\n",
    "result_dir = os.path.join(os.path.dirname(os.getcwd()), 'results/lyrics') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "有天半夜曾经能甦怎么擁抱\n",
      "要不要對一個太在勇敢轉進着的小\n",
      "\n",
      "Because you\n",
      "跟着时光的倒叙叶 覺得38忘记\n",
      "愛我的性格 诺言郭富城\n",
      "扫腿电影 妳的帥 老得快\n",
      "我寧願當一個醜八怪 眼淚\n",
      "梨：\n",
      "但丟失掉自我\n",
      "今天特別逆料\n",
      "樂極老卡路\n",
      "\n",
      "她不愛你　愛其實你去少\n",
      "是不是 多久什么我是路上的脾气\n",
      "你情难沙漠之舟\n",
      "呼吸后疯了渡成了妖难\n",
      "要時間獻技的手\n",
      "来 左边 跟我壹壹\n",
      "宇宙 左边 想聽見妳的挽留\n",
      "春風秋雨飄飄落落只為寂寞\n",
      "長的聚會仿佛在緊緊得\n",
      "Ohoh 这相互要爱情\n",
      "把整個痛\n",
      "服下 一場奇蹟 一線无法誰的 來的撕心裂肺\n",
      "永远永遠 久了孤單\n",
      "不在一起看帶不是你\n",
      "回忆的人 不要说声对不起\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Genearte using RNN model\n",
    "lyrics_rnn = generate_text(model_rnn, u'\\n', temperature = 1.1, num_generate = 200)\n",
    "print(lyrics_rnn)\n",
    "with open(os.path.join(result_dir, 'lyrics_rnn.txt'), 'w') as f:\n",
    "    f.write(lyrics_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "失去雖俏扛起親愛的低著頭幽幽連眼淚全世界南方潮起潮落白牆藍橋浮語白昼鶴樓落向火驚喜會试着连手打开相互落以后距離和哀愁\n",
      "带你話　只想揹著她的夢\n",
      "一步步向前走 她給的永遠 不重\n",
      "那一眼 滿載星海\n",
      "\n",
      "\n",
      "早安 Because you have to believe\n",
      "不要再懷疑\n",
      "或許\n",
      "留下遺憾\n",
      "也算人只為 使我长大\n",
      "成就你现在是你\n",
      "榮華是你 全部都是你\n",
      "心裡想的想的 全部都是你\n",
      "全部都是你 一天\n",
      "親愛的老天不要離別的最后失落\n",
      "就 想自己\n",
      "夢吃回憶 全都不仅仅 長了 一个不是你\n",
      "不說我了這樣 我也還在路上 誰見你会新的街\n",
      "最后流放在你心里\n",
      "明天就是知道你过吃歌\n",
      "\n",
      "你了遺症　陪我度餘生\n",
      "你無關痛癢\n",
      "轉啊轉啊轉啊轉啊轉\n",
      "樂極时光不明白了的计算\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate using LSTM model\n",
    "lyrics_lstm = generate_text(model_lstm, u'\\n', temperature = 1.1, num_generate = 200)\n",
    "print(lyrics_lstm)\n",
    "with open(os.path.join(result_dir, 'lyrics_lstm.txt'), \"w\") as f:\n",
    "    f.write(lyrics_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://github.com/fxsjy/jieba\n",
    "- https://github.com/roberttwomey/dsc160-code/blob/master/examples/text-generation-rnn.ipynb\n",
    "- https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/layers/CuDNNLSTM\n",
    "- https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/layers/CuDNNGRU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
