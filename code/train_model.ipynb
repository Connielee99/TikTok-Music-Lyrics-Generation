{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sic100/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('2new-weights-improvement-33-3.2389-bigger.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"new-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=50, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "    n=0\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        n+=1\n",
    "        print(n)\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes_new', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(\"midi_songs/*.mid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Parsing midi_songs/大田後生仔.wav.mid\n",
      "2\n",
      "Parsing midi_songs/說散就散.wav.mid\n",
      "3\n",
      "Parsing midi_songs/透明.wav.mid\n",
      "4\n",
      "Parsing midi_songs/123我愛你.wav.mid\n",
      "5\n",
      "Parsing midi_songs/多想在平庸的生活擁抱你.wav.mid\n",
      "6\n",
      "Parsing midi_songs/MOM.wav.mid\n",
      "7\n",
      "Parsing midi_songs/你说.wav.mid\n",
      "8\n",
      "Parsing midi_songs/病變.wav.mid\n",
      "9\n",
      "Parsing midi_songs/醉赤壁.wav.mid\n",
      "10\n",
      "Parsing midi_songs/你保护世界我保护你.wav.mid\n",
      "11\n",
      "Parsing midi_songs/晚安.wav.mid\n",
      "12\n",
      "Parsing midi_songs/38度6.wav.mid\n",
      "13\n",
      "Parsing midi_songs/學貓叫.wav.mid\n",
      "14\n",
      "Parsing midi_songs/最天使.wav.mid\n",
      "15\n",
      "Parsing midi_songs/芒種.wav.mid\n",
      "16\n",
      "Parsing midi_songs/纸短情长.wav.mid\n",
      "17\n",
      "Parsing midi_songs/講真的.wav.mid\n",
      "18\n",
      "Parsing midi_songs/剛好遇見你.wav.mid\n",
      "19\n",
      "Parsing midi_songs/空空如也.wav.mid\n",
      "20\n",
      "Parsing midi_songs/疑心病.wav.mid\n",
      "21\n",
      "Parsing midi_songs/體面.wav.mid\n",
      "22\n",
      "Parsing midi_songs/野狼disco.wav.mid\n",
      "23\n",
      "Parsing midi_songs/綠色.wav.mid\n",
      "24\n",
      "Parsing midi_songs/重生.wav.mid\n",
      "25\n",
      "Parsing midi_songs/除了春天爱情和樱花.wav.mid\n",
      "26\n",
      "Parsing midi_songs/一千零一次我愛你.wav.mid\n",
      "27\n",
      "Parsing midi_songs/告白氣球.wav.mid\n",
      "28\n",
      "Parsing midi_songs/愛你.wav.mid\n",
      "29\n",
      "Parsing midi_songs/来不及.wav.mid\n",
      "30\n",
      "Parsing midi_songs/LastDance.wav.mid\n",
      "31\n",
      "Parsing midi_songs/梨渦淺笑.wav.mid\n",
      "32\n",
      "Parsing midi_songs/蓝.wav.mid\n",
      "33\n",
      "Parsing midi_songs/你要相信這不是最後一天.wav.mid\n",
      "34\n",
      "Parsing midi_songs/再也遇不到你這樣的人.wav.mid\n",
      "35\n",
      "Parsing midi_songs/處處吻.wav.mid\n",
      "36\n",
      "Parsing midi_songs/想見你想見你想見你.wav.mid\n",
      "37\n",
      "Parsing midi_songs/可能否.wav.mid\n",
      "38\n",
      "Parsing midi_songs/後來遇見他.wav.mid\n",
      "39\n",
      "Parsing midi_songs/那女孩對我說.wav.mid\n",
      "40\n",
      "Parsing midi_songs/過客.wav.mid\n",
      "41\n",
      "Parsing midi_songs/9420.wav.mid\n",
      "42\n",
      "Parsing midi_songs/喜欢你.wav.mid\n",
      "43\n",
      "Parsing midi_songs/我願意平凡的陪在你身旁.wav.mid\n",
      "44\n",
      "Parsing midi_songs/你的酒館對我打了烊.wav.mid\n",
      "45\n",
      "Parsing midi_songs/和你的每一天.wav.mid\n",
      "46\n",
      "Parsing midi_songs/我在人民广场吃炸鸡.wav.mid\n",
      "47\n",
      "Parsing midi_songs/不僅僅是喜歡.wav.mid\n",
      "48\n",
      "Parsing midi_songs/像鱼.wav.mid\n",
      "49\n",
      "Parsing midi_songs/爱你3000.wav.mid\n",
      "50\n",
      "Parsing midi_songs/追光者.wav.mid\n",
      "51\n",
      "Parsing midi_songs/可不可以.wav.mid\n",
      "52\n",
      "Parsing midi_songs/下山.wav.mid\n",
      "53\n",
      "Parsing midi_songs/全部都是你.wav.mid\n",
      "54\n",
      "Parsing midi_songs/岁岁平安.wav.mid\n",
      "55\n",
      "Parsing midi_songs/你的答案.wav.mid\n",
      "56\n",
      "Parsing midi_songs/无关于你.wav.mid\n",
      "57\n",
      "Parsing midi_songs/卡路里.wav.mid\n",
      "58\n",
      "Parsing midi_songs/答案.wav.mid\n",
      "59\n",
      "Parsing midi_songs/往後餘生.wav.mid\n",
      "60\n",
      "Parsing midi_songs/夏天的風.wav.mid\n",
      "61\n",
      "Parsing midi_songs/沙漠骆驼.wav.mid\n",
      "62\n",
      "Parsing midi_songs/最美的期待.wav.mid\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get amount of pitch names\n",
    "n_vocab = len(set(notes))\n",
    "\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "model = load_model('new-weights-improvement-50-3.4214-bigger.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6684502494543449537\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11714348434584700205\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10990990132\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2219939124139933076\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5280113212374629939\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"2new-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=50, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "227936/227936 [==============================] - 493s 2ms/step - loss: 3.4181\n",
      "Epoch 2/50\n",
      "227936/227936 [==============================] - 494s 2ms/step - loss: 3.4155\n",
      "Epoch 3/50\n",
      "227936/227936 [==============================] - 487s 2ms/step - loss: 3.4019\n",
      "Epoch 4/50\n",
      "227936/227936 [==============================] - 488s 2ms/step - loss: 3.4023\n",
      "Epoch 5/50\n",
      "227936/227936 [==============================] - 489s 2ms/step - loss: 3.3951\n",
      "Epoch 6/50\n",
      "227936/227936 [==============================] - 490s 2ms/step - loss: 3.3884\n",
      "Epoch 7/50\n",
      "227936/227936 [==============================] - 493s 2ms/step - loss: 3.3784\n",
      "Epoch 8/50\n",
      "227936/227936 [==============================] - 491s 2ms/step - loss: 3.3713\n",
      "Epoch 9/50\n",
      "227936/227936 [==============================] - 494s 2ms/step - loss: 3.3622\n",
      "Epoch 10/50\n",
      "227936/227936 [==============================] - 496s 2ms/step - loss: 3.3592\n",
      "Epoch 11/50\n",
      "227936/227936 [==============================] - 496s 2ms/step - loss: 3.3555\n",
      "Epoch 12/50\n",
      "227936/227936 [==============================] - 493s 2ms/step - loss: 3.3449\n",
      "Epoch 13/50\n",
      "227936/227936 [==============================] - 492s 2ms/step - loss: 3.3467\n",
      "Epoch 14/50\n",
      "227936/227936 [==============================] - 493s 2ms/step - loss: 3.3366\n",
      "Epoch 15/50\n",
      "227936/227936 [==============================] - 495s 2ms/step - loss: 3.3297\n",
      "Epoch 16/50\n",
      "227936/227936 [==============================] - 494s 2ms/step - loss: 3.3339\n",
      "Epoch 17/50\n",
      "227936/227936 [==============================] - 492s 2ms/step - loss: 3.3308\n",
      "Epoch 18/50\n",
      "227936/227936 [==============================] - 496s 2ms/step - loss: 3.3281\n",
      "Epoch 19/50\n",
      "227936/227936 [==============================] - 495s 2ms/step - loss: 3.3237\n",
      "Epoch 20/50\n",
      "227936/227936 [==============================] - 497s 2ms/step - loss: 3.3087\n",
      "Epoch 21/50\n",
      "227936/227936 [==============================] - 491s 2ms/step - loss: 3.3053\n",
      "Epoch 22/50\n",
      "227936/227936 [==============================] - 487s 2ms/step - loss: 3.3010\n",
      "Epoch 23/50\n",
      "227936/227936 [==============================] - 490s 2ms/step - loss: 3.2955\n",
      "Epoch 24/50\n",
      "227936/227936 [==============================] - 496s 2ms/step - loss: 3.2907\n",
      "Epoch 25/50\n",
      "215808/227936 [===========================>..] - ETA: 26s - loss: 3.2899"
     ]
    }
   ],
   "source": [
    "train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references:\n",
    "* https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "* https://github.com/Skuldur/Classical-Piano-Composer\n",
    "* https://keras.io/api/layers/recurrent_layers/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
